{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxj8yVh4mFl5"
      },
      "source": [
        "## The Dataset\n",
        "  \n",
        "This MNIST dataset contains a lot of examples:\n",
        "\n",
        "* The MNIST training set contains 60,000 examples.\n",
        "* The MNIST test set contains 10,000 examples.\n",
        "\n",
        "Each example contains a pixel map showing how a person wrote a digit. For example, the following images shows how a person wrote the digit `1` and how that digit might be represented in a 14x14 pixel map (after the input data is normalized). \n",
        "\n",
        "![Two images. The first image shows a somewhat fuzzy digit one. The second image shows a 14x14 floating-point array in which most of the cells contain 0 but a few cells contain values between 0.0 and 1.0. The pattern of nonzero values corresponds to the image of the fuzzy digit in the first image.](https://www.tensorflow.org/images/MNIST-Matrix.png)\n",
        "\n",
        "Each example in the MNIST dataset consists of:\n",
        "\n",
        "* A label specified by a [rater](https://developers.google.com/machine-learning/glossary/#rater).  Each label must be an integer from 0 to 9.  For example, in the preceding image, the rater would almost certainly assign the label `1` to the example.\n",
        "* A 28x28 pixel map, where each pixel is an integer between 0 and 255. The pixel values are on a gray scale in which 0 represents white, 255 represents black, and values between 0 and 255 represent various shades of gray.  \n",
        "\n",
        "This is a multi-class classification problem with 10 output classes, one for each digit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM75uNH-sTv2"
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n9_cTveKmse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a37465be-a755-4aff-d94b-a592633f9da4"
      },
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "# The following line improves formatting when ouputting NumPy arrays.\n",
        "np.set_printoptions(linewidth = 200)\n",
        "\n",
        "print(\"tf version \",tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version  2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A5a4rUlgILM",
        "outputId": "6ba7c70e-34b0-45ec-8f5e-886a11da0ac2"
      },
      "source": [
        "# Google colab Kaggle integration\r\n",
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUFIJ79FggZ3",
        "outputId": "ccdf255e-ec5a-42f3-c3b4-276c656779dc"
      },
      "source": [
        "!ls -al\r\n",
        "!mkdir .kaggle\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Jan  1 17:07 .\n",
            "drwxr-xr-x 1 root root 4096 Jan  1 16:58 ..\n",
            "drwxr-xr-x 1 root root 4096 Dec 21 17:29 .config\n",
            "drwxr-xr-x 2 root root 4096 Jan  1 17:07 .kaggle\n",
            "drwxr-xr-x 1 root root 4096 Dec 21 17:29 sample_data\n",
            "mkdir: cannot create directory ‚Äò.kaggle‚Äô: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNasuSLihBfW"
      },
      "source": [
        "import json\r\n",
        "token = {'username':'matucker','key':'6cc01e29e4aac2d8f2a68956b5944bd0'}\r\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\r\n",
        "    json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lffIi3pBidTN",
        "outputId": "3871a016-f84f-4721-e423-458d77cc5885"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\r\n",
        "!chmod 600 /root/.kaggle/kaggle.json\r\n",
        "!ls -al .kaggle\r\n",
        "!kaggle config set -n path -v{/content}\r\n",
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12\n",
            "drwxr-xr-x 2 root root 4096 Jan  1 17:07 .\n",
            "drwxr-xr-x 1 root root 4096 Jan  1 17:07 ..\n",
            "-rw-r--r-- 1 root root   67 Jan  1 17:07 kaggle.json\n",
            "- path is now set to: {/content}\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "ref                                                            title                                               size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "arashnic/hr-analytics-job-change-of-data-scientists            HR Analytics: Job Change of Data Scientists        295KB  2020-12-07 00:25:10           2026  \n",
            "utkarshxy/who-worldhealth-statistics-2020-complete             World Health 2020 üåè | For Geospatial Analysis        1MB  2021-01-01 15:16:17             76  \n",
            "babyoda/access-to-computers-from-home-oecd                     Access to Computers From Home OECD                   3KB  2020-12-04 10:50:09            191  \n",
            "shashwatwork/impact-of-covid19-pandemic-on-the-global-economy  Impact of Covid-19 Pandemic on the Global Economy    1MB  2020-11-29 14:16:30           1136  \n",
            "emmanuelleai/world-marathons-majors                            World Marathons Majors                               7KB  2020-12-06 19:24:28            206  \n",
            "mrmorj/dataset-of-songs-in-spotify                             Dataset of songs in Spotify                          3MB  2020-12-06 09:46:55            661  \n",
            "boramalper/scihub-papers                                       Sci-Hub Papers                                       6GB  2020-12-06 04:10:54             15  \n",
            "juicobowley/drake-lyrics                                       Drake Lyrics                                       764KB  2020-11-27 01:00:52            121  \n",
            "kavisekar/oecd-unemployment-rate-2020                          OECD Unemployment rate (2020)                        3KB  2020-12-07 15:37:38            186  \n",
            "kingabzpro/datascience-survey-on-kaggle                        data science survey on Kaggle                      129KB  2020-11-24 19:04:19            132  \n",
            "sakshigoyal7/credit-card-customers                             Credit Card customers                              379KB  2020-11-19 07:38:44          12964  \n",
            "szymonjanowski/internet-articles-data-with-users-engagement    Internet news data with readers engagement           3MB  2020-11-21 17:09:57           3545  \n",
            "sootersaalu/amazon-top-50-bestselling-books-2009-2019          Amazon Top 50 Bestselling Books 2009 - 2019         15KB  2020-10-13 09:39:21          10917  \n",
            "alexgude/california-traffic-collision-data-from-switrs         California Traffic Collision Data from SWITRS        1GB  2020-11-22 16:51:55           2193  \n",
            "babyoda/women-entrepreneurship-and-labor-force                 Women Entrepreneurship and Labor Force               1KB  2020-11-21 08:38:51           5218  \n",
            "shivamb/netflix-shows                                          Netflix Movies and TV Shows                        971KB  2020-01-20 07:33:56          77448  \n",
            "yamaerenay/spotify-dataset-19212020-160k-tracks                Spotify Dataset 1921-2020, 160k+ Tracks             16MB  2020-11-25 21:14:12          13380  \n",
            "patrickb1912/ipl-complete-dataset-20082020                     IPL Complete Dataset (2008-2020)                     1MB  2020-11-23 06:53:37           2846  \n",
            "manchunhui/us-election-2020-tweets                             US Election 2020 Tweets                            353MB  2020-11-09 18:51:59           5531  \n",
            "imoore/2020-us-general-election-turnout-rates                  2020 US General Election Turnout rates               4KB  2020-11-26 00:21:15           3685  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFashL_wj_Bn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37900a50-56c8-485f-cb98-f7789e11e211"
      },
      "source": [
        "!kaggle datasets list -s sign"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "ref                                                           title                                                size  lastUpdated          downloadCount  \n",
            "------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  \n",
            "datamunge/sign-language-mnist                                 Sign Language MNIST                                  63MB  2017-10-20 15:09:18          35038  \n",
            "ardamavi/sign-language-digits-dataset                         Sign Language Digits Dataset                         17MB  2017-12-24 16:08:56          15583  \n",
            "valentynsichkar/traffic-signs-preprocessed                    Traffic Signs Preprocessed                            4GB  2019-08-31 18:22:11           4529  \n",
            "meowmeowmeowmeowmeow/gtsrb-german-traffic-sign                GTSRB - German Traffic Sign Recognition Benchmark   612MB  2018-11-25 18:12:34          22049  \n",
            "usgs/earthquake-database                                      Significant Earthquakes, 1965-2016                  590KB  2017-01-26 20:14:10          18024  \n",
            "grassknoted/asl-alphabet                                      ASL Alphabet                                          1GB  2018-04-22 19:31:36          17239  \n",
            "divyanshrai/handwritten-signatures                            handwritten signatures                              370MB  2018-11-08 05:27:21           3425  \n",
            "robinreni/signature-verification-dataset                      Signature_Verification_Dataset                      601MB  2019-01-24 16:20:38           2567  \n",
            "andrewmvd/road-sign-detection                                 Road Sign Detection                                 218MB  2020-05-24 01:51:18            486  \n",
            "mohitkr05/global-significant-earthquake-database-from-2150bc  Global Significant Earthquake Database from 2150BC  216KB  2020-06-08 09:41:18            766  \n",
            "feronial/turkish-sign-languagefinger-spelling                 Turkish Sign Language (Fingerspelling)              560MB  2018-05-16 10:04:28            414  \n",
            "unanimad/us-election-2020                                     US Election 2020                                    429KB  2020-12-28 21:12:35          12037  \n",
            "ahmedkhanak1995/sign-language-gesture-images-dataset          Sign Language Gesture Images Dataset                191MB  2019-09-10 20:54:35            852  \n",
            "ash2703/handsignimages                                        hand-sign-images                                     23MB  2020-04-07 10:22:31            227  \n",
            "ayuraj/asl-dataset                                            American Sign Language Dataset                       57MB  2019-04-28 08:25:27            491  \n",
            "mrgeislinger/asl-rgb-depth-fingerspelling-spelling-it-out     ASL Fingerspelling Images (RGB & Depth)               2GB  2019-12-17 02:52:11            536  \n",
            "valentynsichkar/traffic-signs-dataset-in-yolo-format          Traffic Signs Dataset in YOLO format                250MB  2020-04-03 22:25:16           1085  \n",
            "rtatman/5day-data-challenge-signup-survey-responses           5-Day Data Challenge Sign-Up Survey Responses        63KB  2017-12-13 00:09:15            556  \n",
            "muhammadkhalid/sign-language-for-alphabets                    Sign Language for Alphabets                          98MB  2019-11-14 20:06:56            246  \n",
            "dmitryyemelyanov/chinese-traffic-signs                        Chinese Traffic Signs                               185MB  2020-04-16 19:42:40            208  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpn_-aVzlBpf",
        "outputId": "ed6e2f02-6a86-40e2-daa2-a8db38ecb005"
      },
      "source": [
        "!kaggle datasets download -d datamunge/sign-language-mnist -p /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sign-language-mnist.zip to /content\n",
            " 78% 49.0M/62.6M [00:02<00:01, 12.2MB/s]\n",
            "100% 62.6M/62.6M [00:02<00:00, 23.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onyd1_SXlMhg",
        "outputId": "0a33397e-1f40-44dc-86a7-cff25604e93d"
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sign-language-mnist.zip\n",
            "  inflating: amer_sign2.png          \n",
            "  inflating: amer_sign3.png          \n",
            "  inflating: american_sign_language.PNG  \n",
            "  inflating: sign_mnist_test.csv     \n",
            "  inflating: sign_mnist_test/sign_mnist_test.csv  \n",
            "  inflating: sign_mnist_train.csv    \n",
            "  inflating: sign_mnist_train/sign_mnist_train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6b5cF1U7aTd",
        "outputId": "25c05273-43fb-49db-c4f1-e70e68408d35"
      },
      "source": [
        "!ls -al\r\n",
        "!pwd\r\n",
        "!ls -al sign_mnist_train\r\n",
        "!ls -al sign_mnist_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 167456\n",
            "drwxr-xr-x 1 root root     4096 Jan  1 17:09 .\n",
            "drwxr-xr-x 1 root root     4096 Jan  1 16:58 ..\n",
            "-rw-r--r-- 1 root root   208007 Sep 21  2019 american_sign_language.PNG\n",
            "-rw-r--r-- 1 root root   487452 Sep 21  2019 amer_sign2.png\n",
            "-rw-r--r-- 1 root root    44527 Sep 21  2019 amer_sign3.png\n",
            "drwxr-xr-x 1 root root     4096 Dec 21 17:29 .config\n",
            "drwxr-xr-x 2 root root     4096 Jan  1 17:07 .kaggle\n",
            "drwxr-xr-x 1 root root     4096 Dec 21 17:29 sample_data\n",
            "-rw-r--r-- 1 root root 65633206 Jan  1 17:09 sign-language-mnist.zip\n",
            "drwxr-xr-x 2 root root     4096 Jan  1 17:09 sign_mnist_test\n",
            "-rw-r--r-- 1 root root 21777485 Sep 21  2019 sign_mnist_test.csv\n",
            "drwxr-xr-x 2 root root     4096 Jan  1 17:09 sign_mnist_train\n",
            "-rw-r--r-- 1 root root 83281065 Sep 21  2019 sign_mnist_train.csv\n",
            "/content\n",
            "total 81340\n",
            "drwxr-xr-x 2 root root     4096 Jan  1 17:09 .\n",
            "drwxr-xr-x 1 root root     4096 Jan  1 17:09 ..\n",
            "-rw-r--r-- 1 root root 83281065 Sep 21  2019 sign_mnist_train.csv\n",
            "total 21276\n",
            "drwxr-xr-x 2 root root     4096 Jan  1 17:09 .\n",
            "drwxr-xr-x 1 root root     4096 Jan  1 17:09 ..\n",
            "-rw-r--r-- 1 root root 21777485 Sep 21  2019 sign_mnist_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "VAFzBygelk1C",
        "outputId": "17b69118-0d49-4bfd-fdb6-bb6c67f1c984"
      },
      "source": [
        "import pandas as pd\r\n",
        "pd_train = pd.read_csv('sign_mnist_train/sign_mnist_train.csv')\r\n",
        "pd_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>160</td>\n",
              "      <td>163</td>\n",
              "      <td>165</td>\n",
              "      <td>159</td>\n",
              "      <td>166</td>\n",
              "      <td>168</td>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>172</td>\n",
              "      <td>171</td>\n",
              "      <td>171</td>\n",
              "      <td>170</td>\n",
              "      <td>170</td>\n",
              "      <td>169</td>\n",
              "      <td>111</td>\n",
              "      <td>121</td>\n",
              "      <td>129</td>\n",
              "      <td>135</td>\n",
              "      <td>141</td>\n",
              "      <td>144</td>\n",
              "      <td>148</td>\n",
              "      <td>151</td>\n",
              "      <td>154</td>\n",
              "      <td>157</td>\n",
              "      <td>160</td>\n",
              "      <td>...</td>\n",
              "      <td>205</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>205</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>142</td>\n",
              "      <td>151</td>\n",
              "      <td>160</td>\n",
              "      <td>172</td>\n",
              "      <td>196</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>190</td>\n",
              "      <td>135</td>\n",
              "      <td>96</td>\n",
              "      <td>86</td>\n",
              "      <td>77</td>\n",
              "      <td>77</td>\n",
              "      <td>79</td>\n",
              "      <td>176</td>\n",
              "      <td>205</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>157</td>\n",
              "      <td>158</td>\n",
              "      <td>156</td>\n",
              "      <td>154</td>\n",
              "      <td>154</td>\n",
              "      <td>153</td>\n",
              "      <td>152</td>\n",
              "      <td>151</td>\n",
              "      <td>149</td>\n",
              "      <td>149</td>\n",
              "      <td>148</td>\n",
              "      <td>147</td>\n",
              "      <td>146</td>\n",
              "      <td>144</td>\n",
              "      <td>142</td>\n",
              "      <td>143</td>\n",
              "      <td>138</td>\n",
              "      <td>92</td>\n",
              "      <td>108</td>\n",
              "      <td>158</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>159</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>...</td>\n",
              "      <td>100</td>\n",
              "      <td>78</td>\n",
              "      <td>120</td>\n",
              "      <td>157</td>\n",
              "      <td>168</td>\n",
              "      <td>107</td>\n",
              "      <td>99</td>\n",
              "      <td>121</td>\n",
              "      <td>133</td>\n",
              "      <td>97</td>\n",
              "      <td>95</td>\n",
              "      <td>120</td>\n",
              "      <td>135</td>\n",
              "      <td>116</td>\n",
              "      <td>95</td>\n",
              "      <td>79</td>\n",
              "      <td>69</td>\n",
              "      <td>86</td>\n",
              "      <td>139</td>\n",
              "      <td>173</td>\n",
              "      <td>200</td>\n",
              "      <td>185</td>\n",
              "      <td>175</td>\n",
              "      <td>198</td>\n",
              "      <td>124</td>\n",
              "      <td>118</td>\n",
              "      <td>94</td>\n",
              "      <td>140</td>\n",
              "      <td>133</td>\n",
              "      <td>84</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>179</td>\n",
              "      <td>179</td>\n",
              "      <td>179</td>\n",
              "      <td>178</td>\n",
              "      <td>178</td>\n",
              "      <td>109</td>\n",
              "      <td>52</td>\n",
              "      <td>66</td>\n",
              "      <td>77</td>\n",
              "      <td>83</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>203</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>196</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>193</td>\n",
              "      <td>198</td>\n",
              "      <td>166</td>\n",
              "      <td>132</td>\n",
              "      <td>114</td>\n",
              "      <td>89</td>\n",
              "      <td>74</td>\n",
              "      <td>79</td>\n",
              "      <td>77</td>\n",
              "      <td>74</td>\n",
              "      <td>78</td>\n",
              "      <td>132</td>\n",
              "      <td>188</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>206</td>\n",
              "      <td>205</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>209</td>\n",
              "      <td>207</td>\n",
              "      <td>208</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>198</td>\n",
              "      <td>197</td>\n",
              "      <td>195</td>\n",
              "      <td>192</td>\n",
              "      <td>197</td>\n",
              "      <td>171</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>54</td>\n",
              "      <td>212</td>\n",
              "      <td>213</td>\n",
              "      <td>215</td>\n",
              "      <td>215</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>213</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>...</td>\n",
              "      <td>247</td>\n",
              "      <td>242</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>229</td>\n",
              "      <td>227</td>\n",
              "      <td>225</td>\n",
              "      <td>223</td>\n",
              "      <td>221</td>\n",
              "      <td>220</td>\n",
              "      <td>216</td>\n",
              "      <td>58</td>\n",
              "      <td>51</td>\n",
              "      <td>49</td>\n",
              "      <td>50</td>\n",
              "      <td>57</td>\n",
              "      <td>60</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>18</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>159</td>\n",
              "      <td>255</td>\n",
              "      <td>237</td>\n",
              "      <td>239</td>\n",
              "      <td>237</td>\n",
              "      <td>236</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>186</td>\n",
              "      <td>188</td>\n",
              "      <td>189</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>191</td>\n",
              "      <td>189</td>\n",
              "      <td>190</td>\n",
              "      <td>190</td>\n",
              "      <td>187</td>\n",
              "      <td>190</td>\n",
              "      <td>192</td>\n",
              "      <td>193</td>\n",
              "      <td>191</td>\n",
              "      <td>191</td>\n",
              "      <td>192</td>\n",
              "      <td>192</td>\n",
              "      <td>194</td>\n",
              "      <td>194</td>\n",
              "      <td>166</td>\n",
              "      <td>169</td>\n",
              "      <td>172</td>\n",
              "      <td>174</td>\n",
              "      <td>177</td>\n",
              "      <td>180</td>\n",
              "      <td>182</td>\n",
              "      <td>185</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>190</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>77</td>\n",
              "      <td>88</td>\n",
              "      <td>117</td>\n",
              "      <td>123</td>\n",
              "      <td>127</td>\n",
              "      <td>129</td>\n",
              "      <td>134</td>\n",
              "      <td>145</td>\n",
              "      <td>152</td>\n",
              "      <td>156</td>\n",
              "      <td>179</td>\n",
              "      <td>105</td>\n",
              "      <td>106</td>\n",
              "      <td>105</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>104</td>\n",
              "      <td>175</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>152</td>\n",
              "      <td>136</td>\n",
              "      <td>130</td>\n",
              "      <td>136</td>\n",
              "      <td>150</td>\n",
              "      <td>118</td>\n",
              "      <td>92</td>\n",
              "      <td>85</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      3     107     118     127  ...       206       204       203       202\n",
              "1      6     155     157     156  ...       175       103       135       149\n",
              "2      2     187     188     188  ...       198       195       194       195\n",
              "3      2     211     211     212  ...       225       222       229       163\n",
              "4     13     164     167     170  ...       157       163       164       179\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8q0OxaZr3qr"
      },
      "source": [
        "y_train = pd_train[[\"label\"]].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAqTJGMUuYDA",
        "outputId": "5f1ba313-ba55-4c0b-8b46-058b1fc37ac1"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method DataFrame.to_numpy of        label\n",
            "0          3\n",
            "1          6\n",
            "2          2\n",
            "3          2\n",
            "4         13\n",
            "...      ...\n",
            "27450     13\n",
            "27451     23\n",
            "27452     18\n",
            "27453     17\n",
            "27454     23\n",
            "\n",
            "[27455 rows x 1 columns]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr_-7lm_uqf1",
        "outputId": "3992b249-c8ff-48cf-f47b-13518d7bfb97"
      },
      "source": [
        "x_train = pd_train[pd_train.columns[1:]].to_numpy()\r\n",
        "print(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[107 118 127 ... 204 203 202]\n",
            " [155 157 156 ... 103 135 149]\n",
            " [187 188 188 ... 195 194 195]\n",
            " ...\n",
            " [174 174 174 ... 202 200 200]\n",
            " [177 181 184 ...  64  87  93]\n",
            " [179 180 180 ... 205 209 215]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2Iiaelcvnq-",
        "outputId": "b5c9449a-4e31-4262-e9da-083ba0389f90"
      },
      "source": [
        "pd_test = pd.read_csv('sign_mnist_test/sign_mnist_test.csv')\r\n",
        "print(pd_test.head())\r\n",
        "y_test = pd_test[[\"label\"]].to_numpy()\r\n",
        "print(y_test)\r\n",
        "x_test = pd_test[pd_test.columns[1:]].to_numpy()\r\n",
        "print(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
            "0      6     149     149     150  ...       106       112       120       107\n",
            "1      5     126     128     131  ...       184       184       182       180\n",
            "2     10      85      88      92  ...       226       225       224       222\n",
            "3      0     203     205     207  ...       230       240       253       255\n",
            "4      3     188     191     193  ...        49        46        46        53\n",
            "\n",
            "[5 rows x 785 columns]\n",
            "[[ 6]\n",
            " [ 5]\n",
            " [10]\n",
            " ...\n",
            " [ 2]\n",
            " [ 4]\n",
            " [ 2]]\n",
            "[[149 149 150 ... 112 120 107]\n",
            " [126 128 131 ... 184 182 180]\n",
            " [ 85  88  92 ... 225 224 222]\n",
            " ...\n",
            " [190 191 190 ... 211 209 208]\n",
            " [201 205 208 ...  67  70  63]\n",
            " [173 174 173 ... 195 193 192]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_TaJhU4KcuY"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "`tf.keras` provides a set of convenience functions for loading well-known datasets. Each of these convenience functions does the following:\n",
        "\n",
        "* Loads both the training set and the test set.\n",
        "* Separates each set into features and labels.\n",
        "\n",
        "The relevant convenience function for MNIST is called `mnist.load_data()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "630jCwIo7nGT"
      },
      "source": [
        "  # def load_data()\r\n",
        "  # # origin_folder = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'\r\n",
        "  # # path = get_file(\r\n",
        "  # #     path,\r\n",
        "  # #     origin=origin_folder + 'mnist.npz',\r\n",
        "  # #     file_hash=\r\n",
        "  # #     '731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1')\r\n",
        "  # path = 'sign_mnist_train/sign_mnist_train.csv'\r\n",
        "  # with np.load(path, allow_pickle=True) as f:\r\n",
        "  #   x_train, y_train = f['x_train'], f['y_train']\r\n",
        "  #   x_test, y_test = f['x_test'], f['y_test']\r\n",
        "\r\n",
        "  #   return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZlvdpyYKx7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d5bcdc-b43e-4920-fdf6-278c40288b8c"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(\"x_train.size\", x_train.size)\n",
        "print(\"x_train.itemsize\", x_train.itemsize)\n",
        "print(\"x_train.shape\", x_train.shape)\n",
        "print(\"x_test.shape\", x_test.shape)\n",
        "print(\"y_train.shape\", y_train.shape)\n",
        "print(\"y_test.shape\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.size 47040000\n",
            "x_train.itemsize 1\n",
            "x_train.shape (60000, 28, 28)\n",
            "x_test.shape (10000, 28, 28)\n",
            "y_train.shape (60000,)\n",
            "y_test.shape (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CWaE8OjwVul",
        "outputId": "472dcc93-8f48-4601-ad9b-93928095cac1"
      },
      "source": [
        "print(\"x_train.size\", x_train.size)\r\n",
        "print(\"x_train.itemsize\", x_train.itemsize)\r\n",
        "print(\"x_train.shape\", x_train.shape)\r\n",
        "print(\"x_test.shape\", x_test.shape)\r\n",
        "print(\"y_train.shape\", y_train.shape)\r\n",
        "print(\"y_test.shape\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.size 21524720\n",
            "x_train.itemsize 8\n",
            "x_train.shape (27455, 784)\n",
            "x_test.shape (7172, 784)\n",
            "y_train.shape (27455, 1)\n",
            "y_test.shape (7172, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfQkr3hxJGXU"
      },
      "source": [
        "Notice that `mnist.load_data()` returned four separate values:\n",
        "\n",
        "* `x_train` contains the training set's features.\n",
        "* `y_train` contains the training set's labels.\n",
        "* `x_test` contains the test set's features.\n",
        "* `y_test` contains the test set's labels.\n",
        "\n",
        "**Note:** The MNIST .csv training set is already shuffled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71vsSUM7pdmu"
      },
      "source": [
        "## View the dataset\n",
        "\n",
        "The .csv file for the California Housing Dataset contains column names (for example, `latitude`, `longitude`, `population`). By contrast, the .csv file for MNIST does not contain column names. Instead of column names, you use ordinal numbers to access different subsets of the MNIST dataset. In fact, it is probably best to think of `x_train` and `x_test` as three-dimensional NumPy arrays:  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoOhpjkeCL8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a15f2ec-053e-4ef6-b68d-d48fb3485faf"
      },
      "source": [
        "# Output example #2917 of the training set.\n",
        "x_train[2917]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([168, 173, 178, 182, 184, 188, 192, 194, 197, 199, 201, 203, 206, 208, 208, 208, 209, 209, 209, 210, 210, 210, 212, 212, 213, 213, 213, 213, 172, 176, 181, 185, 191, 185, 188, 199, 199, 203,\n",
              "       206, 206, 208, 210, 211, 212, 213, 212, 213, 214, 214, 214, 215, 215, 215, 215, 214, 215, 174, 180, 185, 184, 198, 179, 141, 202, 204, 207, 208, 209, 211, 213, 214, 215, 215, 216, 217, 216,\n",
              "       216, 217, 218, 219, 219, 219, 218, 219, 178, 184, 190, 186, 209, 194, 114, 190, 210, 208, 211, 213, 215, 216, 216, 218, 218, 218, 219, 219, 218, 220, 221, 221, 221, 222, 221, 221, 182, 186,\n",
              "       191, 189, 216, 206, 108, 175, 217, 210, 215, 215, 217, 217, 218, 221, 221, 222, 222, 224, 226, 222, 223, 223, 222, 224, 223, 223, 182, 187, 191, 191, 212, 212, 110, 165, 221, 212, 216, 218,\n",
              "       222, 223, 222, 223, 227, 230, 225, 218, 214, 229, 225, 227, 227, 227, 226, 227, 184, 190, 194, 194, 210, 218, 122, 154, 226, 215, 217, 219, 212, 217, 229, 220, 188, 204, 239, 209, 155, 177,\n",
              "       236, 227, 230, 230, 230, 230, 187, 191, 196, 194, 214, 229, 140, 137, 226, 217, 217, 228, 184, 170, 213, 207, 166, 138, 196, 207, 167, 127, 195, 238, 230, 232, 232, 231, 189, 192, 198, 198,\n",
              "       214, 228, 159, 143, 211, 223, 225, 252, 215, 220, 207, 186, 185, 185, 212, 183, 126, 140, 157, 245, 231, 234, 234, 234, 191, 194, 199, 203, 206, 228, 188, 173, 194, 224, 232, 243, 248, 217,\n",
              "       189, 196, 202, 215, 222, 181, 122, 108, 137, 241, 236, 237, 236, 235, 193, 197, 202, 207, 206, 229, 199, 187, 204, 222, 234, 199, 245, 233, 176, 192, 197, 193, 181, 192, 145,  94, 106, 238,\n",
              "       240, 238, 237, 237, 193, 199, 203, 207, 205, 223, 211, 195, 208, 238, 227, 174, 182, 244, 173, 144, 144, 125, 162, 211, 162, 107, 121, 248, 238, 240, 239, 239, 196, 201, 205, 209, 209, 223,\n",
              "       235, 198, 215, 209, 224, 208, 158, 220, 193, 120,  88, 122, 210, 215, 183, 118, 147, 255, 238, 242, 241, 242, 198, 202, 208, 211, 211, 223, 249, 183, 183, 206, 182, 178, 163, 194, 194, 156,\n",
              "       100,  98, 209, 238, 198, 146, 111, 236, 244, 241, 243, 245, 199, 203, 209, 214, 214, 220, 243, 203, 139, 183, 182, 147, 151, 180, 199, 189, 125,  71, 176, 255, 219, 166,  97, 174, 255, 241,\n",
              "       246, 246, 201, 204, 211, 215, 217, 221, 238, 221, 157, 138, 167, 147, 147, 167, 184, 191, 126, 183, 243, 242, 215, 162, 117, 125, 255, 243, 246, 246, 202, 206, 212, 216, 218, 221, 246, 235,\n",
              "       189, 133, 154, 178, 142, 188, 222, 185, 186, 244, 246, 214, 186, 156, 119, 124, 254, 245, 245, 247, 203, 208, 213, 219, 222, 222, 248, 237, 197, 154, 136, 175, 148, 210, 237, 222, 250, 234,\n",
              "       216, 203, 162, 145, 106, 162, 255, 246, 248, 249, 205, 210, 215, 220, 224, 224, 247, 244, 211, 172, 137, 164, 163, 206, 236, 241, 253, 231, 196, 176, 152, 127,  96, 216, 255, 249, 250, 251,\n",
              "       208, 211, 218, 221, 223, 225, 248, 251, 221, 180, 147, 175, 173, 206, 243, 246, 237, 212, 183, 161, 139, 111, 117, 252, 253, 252, 252, 252, 207, 213, 218, 221, 226, 227, 247, 255, 234, 189,\n",
              "       162, 190, 180, 196, 249, 246, 225, 200, 174, 155, 132,  95, 161, 255, 250, 253, 252, 253, 208, 215, 220, 222, 226, 227, 249, 255, 251, 203, 182, 206, 176, 195, 242, 246, 231, 199, 166, 144,\n",
              "       122,  92, 208, 255, 250, 254, 255, 255, 210, 216, 219, 223, 225, 227, 238, 255, 255, 216, 199, 217, 173, 203, 226, 250, 223, 189, 155, 132, 110, 106, 245, 255, 253, 255, 255, 255, 211, 216,\n",
              "       220, 224, 227, 229, 225, 249, 254, 228, 210, 221, 177, 200, 229, 237, 209, 171, 137, 120,  96, 146, 255, 255, 255, 255, 255, 255, 211, 217, 222, 225, 227, 232, 228, 226, 243, 233, 218, 211,\n",
              "       195, 170, 232, 220, 188, 152, 125, 114,  90, 212, 255, 255, 255, 255, 255, 255, 212, 216, 221, 224, 227, 232, 235, 219, 231, 229, 214, 196, 192, 165, 197, 215, 169, 135, 121,  98, 127, 255,\n",
              "       255, 255, 255, 255, 255, 255, 211, 215, 221, 224, 228, 233, 238, 218, 232, 226, 208, 188, 176, 161, 166, 191, 165, 134, 119,  93, 205, 255, 255, 255, 255, 251, 226, 221, 211, 215, 221, 224,\n",
              "       229, 232, 236, 218, 229, 208, 190, 184, 170, 155, 152, 165, 165, 135, 106, 131, 255, 255, 253, 255, 226, 208, 181, 160])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNJrJKUwvZMR"
      },
      "source": [
        "Alternatively, you can call `matplotlib.pyplot.imshow` to interpret the preceding numeric array as an image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siRC8a1hJvmq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "521bfe6c-2c4a-48ef-c8dd-a636e0f3a158"
      },
      "source": [
        "# Use false colors to visualize the array.\n",
        "plt.imshow(x_train[2917])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e76051f2bab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use false colors to visualize the array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2917\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (784,) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-he9IcihDxb"
      },
      "source": [
        "# Output row #10 of example #2917.\n",
        "x_train[2917][10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUEWipalhQ8J"
      },
      "source": [
        "# Output pixel #16 of row #10 of example #2900.\n",
        "x_train[2917][10][16]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ldP-5z1B2vL"
      },
      "source": [
        "## Task 1: Normalize feature values\n",
        "\n",
        "Complete the following code cell to map each feature value from its current representation (an integer between 0 and 255) to a floating-point value between 0 and 1.0. Store the floating-point values in `x_train_normalized` and `x_test_normalized`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YQljE-wizDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f78fcdf-5bcf-4205-ffcf-71cf7115685e"
      },
      "source": [
        "x_train_normalized = x_train/255.0\n",
        "x_test_normalized = x_test/255.0 \n",
        "print(x_train_normalized[2900][10]) # Output a normalized row"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5725490196078431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8HC-TDgB1D1"
      },
      "source": [
        "#@title Double-click to see a solution to Task 1. \n",
        "\n",
        "x_train_normalized = x_train / 255.0\n",
        "x_test_normalized = x_test / 255.0\n",
        "print(x_train_normalized[2900][12]) # Output a normalized row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBWRF6CStuNA"
      },
      "source": [
        "## Define a plotting function\n",
        "\n",
        "The following function plots an accuracy curve:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF0BFRXTOeR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea06ad5-095b-4ec6-c42d-821f402e55e3"
      },
      "source": [
        "#@title Define the plotting function\n",
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
        "  # list_of_metrics should be one of the names shown in:\n",
        "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  for m in list_of_metrics:\n",
        "    x = hist[m]\n",
        "    plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "print(\"Loaded the plot_curve function.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the plot_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3014ezH3C7jT"
      },
      "source": [
        "## Create a deep neural net model\n",
        "\n",
        "The `create_model` function defines the topography of the deep neural net, specifying the following:\n",
        "\n",
        "* The number of [layers](https://developers.google.com/machine-learning/glossary/#layer) in the deep neural net.\n",
        "* The number of [nodes](https://developers.google.com/machine-learning/glossary/#node) in each layer.\n",
        "* Any [regularization](https://developers.google.com/machine-learning/glossary/#regularization) layers.\n",
        "\n",
        "The `create_model` function also defines the [activation function](https://developers.google.com/machine-learning/glossary/#activation_function) of each layer.  The activation function of the output layer is [softmax](https://developers.google.com/machine-learning/glossary/#softmax), which will yield 10 different outputs for each example. Each of the 10 outputs provides the probability that the input example is a certain digit.\n",
        "\n",
        "**Note:** Unlike several of the recent Colabs, this exercise does not define feature columns or a feature layer.  Instead, the model will train on the NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pedD5GhlDC-y",
        "cellView": "both"
      },
      "source": [
        "def create_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "  #node_count = 32  # 96%\n",
        "  #node_count = 64   # 97%\n",
        "  #node_count = 128   # 97.97%\n",
        "  node_count = 256   # 98.34%\n",
        "  # All models in this course are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # The features are stored in a two-dimensional 28X28 array. \n",
        "  # Flatten that two-dimensional array into a a one-dimensional \n",
        "  # 784-element array.\n",
        "  # MAT-> already flattened\n",
        "  #model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Define the first hidden layer.   95%\n",
        "  model.add(tf.keras.layers.Dense(units=node_count, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  #model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "  #model.add(tf.keras.layers.Dropout(rate=0.02)) #97.50%\n",
        "  model.add(tf.keras.layers.Dropout(rate=0.4)) #97.82%\n",
        "  #model.add(tf.keras.layers.Dropout(rate=0.8)) #95.5%\n",
        "\n",
        "  # 2nd hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=node_count, activation='relu'))\n",
        "\n",
        "  # 3rd hidden layer.   96%\n",
        "  model.add(tf.keras.layers.Dense(units=node_count, activation='relu'))\n",
        "\n",
        "  # # 4th hidden layer.   \n",
        "  # model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "  # # 5th hidden layer.   \n",
        "  # model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "  # # 6th hidden layer.   95.98%\n",
        "  # model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "  # Define the output layer. The units parameter is set to 10 because\n",
        "  # the model must choose among 10 possible output values (representing\n",
        "  # the digits from 0 to 9, inclusive).\n",
        "  #\n",
        "  # Don't change this layer.\n",
        "  # MAT-> 24 labels\n",
        "  model.add(tf.keras.layers.Dense(units=25, activation='softmax'))     \n",
        "                           \n",
        "  # Construct the layers into a model that TensorFlow can execute.  \n",
        "  # Notice that the loss function for multi-class classification\n",
        "  # is different than the loss function for binary classification.  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model    \n",
        "\n",
        "\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.1):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True, \n",
        "                      validation_split=validation_split)\n",
        " \n",
        "  # To track the progression of training, gather a snapshot\n",
        "  # of the model's metrics at each epoch. \n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-IXYVfvM4gD"
      },
      "source": [
        "## Invoke the previous functions\n",
        "\n",
        "Run the following code cell to invoke the preceding functions and actually train the model on the training set. \n",
        "\n",
        "**Note:** Due to several factors (for example, more examples and a more complex neural network) training MNIST might take longer than training the California Housing Dataset. Be patient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj3v5EKQFY8s",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f484175-8ca1-4c1b-dda6-0c981192a066"
      },
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.003\n",
        "epochs = 50\n",
        "batch_size = 4000\n",
        "validation_split = 0.2\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
        "                           epochs, batch_size, validation_split)\n",
        "\n",
        "# Plot a graph of the metric vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 2s 228ms/step - loss: 3.3016 - accuracy: 0.0463 - val_loss: 3.1600 - val_accuracy: 0.0506\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 1s 147ms/step - loss: 3.1507 - accuracy: 0.0636 - val_loss: 2.9987 - val_accuracy: 0.1155\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 1s 137ms/step - loss: 2.9814 - accuracy: 0.1161 - val_loss: 2.6875 - val_accuracy: 0.2231\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 2.7833 - accuracy: 0.1635 - val_loss: 2.5530 - val_accuracy: 0.2413\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 2.5775 - accuracy: 0.2094 - val_loss: 2.2374 - val_accuracy: 0.3324\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 2.3529 - accuracy: 0.2623 - val_loss: 1.9919 - val_accuracy: 0.3897\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 2.1541 - accuracy: 0.3082 - val_loss: 1.8091 - val_accuracy: 0.4247\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 1s 134ms/step - loss: 2.0078 - accuracy: 0.3420 - val_loss: 1.6879 - val_accuracy: 0.4828\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 1s 146ms/step - loss: 1.9320 - accuracy: 0.3649 - val_loss: 1.5712 - val_accuracy: 0.5028\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 1.8050 - accuracy: 0.3930 - val_loss: 1.5901 - val_accuracy: 0.4868\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 1.7571 - accuracy: 0.4148 - val_loss: 1.4418 - val_accuracy: 0.5343\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 1.6455 - accuracy: 0.4443 - val_loss: 1.2807 - val_accuracy: 0.5926\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 1.5696 - accuracy: 0.4678 - val_loss: 1.2242 - val_accuracy: 0.6064\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 1s 137ms/step - loss: 1.5072 - accuracy: 0.4845 - val_loss: 1.1900 - val_accuracy: 0.6013\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 1.5127 - accuracy: 0.4819 - val_loss: 1.1912 - val_accuracy: 0.5866\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 1.5059 - accuracy: 0.4825 - val_loss: 1.1502 - val_accuracy: 0.6150\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 1s 134ms/step - loss: 1.4349 - accuracy: 0.5053 - val_loss: 1.0551 - val_accuracy: 0.6744\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 1.3433 - accuracy: 0.5340 - val_loss: 0.9937 - val_accuracy: 0.6640\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 1s 146ms/step - loss: 1.2891 - accuracy: 0.5522 - val_loss: 0.9496 - val_accuracy: 0.6933\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 1.2413 - accuracy: 0.5634 - val_loss: 0.8549 - val_accuracy: 0.7379\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 1.1781 - accuracy: 0.5868 - val_loss: 0.8380 - val_accuracy: 0.7367\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 1s 137ms/step - loss: 1.1457 - accuracy: 0.6015 - val_loss: 0.7534 - val_accuracy: 0.7864\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 1.0901 - accuracy: 0.6197 - val_loss: 0.7338 - val_accuracy: 0.7884\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 1s 147ms/step - loss: 1.0583 - accuracy: 0.6293 - val_loss: 0.6865 - val_accuracy: 0.8039\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 1.0097 - accuracy: 0.6443 - val_loss: 0.6568 - val_accuracy: 0.7997\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 1s 138ms/step - loss: 0.9923 - accuracy: 0.6525 - val_loss: 0.6445 - val_accuracy: 0.8053\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 1.0113 - accuracy: 0.6378 - val_loss: 0.6736 - val_accuracy: 0.8059\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 1s 138ms/step - loss: 1.0111 - accuracy: 0.6399 - val_loss: 0.6433 - val_accuracy: 0.8037\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 1s 143ms/step - loss: 1.0457 - accuracy: 0.6269 - val_loss: 0.5946 - val_accuracy: 0.8133\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 1.0062 - accuracy: 0.6378 - val_loss: 0.6075 - val_accuracy: 0.8237\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 1.0145 - accuracy: 0.6352 - val_loss: 0.5786 - val_accuracy: 0.8266\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 1s 137ms/step - loss: 0.9193 - accuracy: 0.6717 - val_loss: 0.5371 - val_accuracy: 0.8355\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 0.8959 - accuracy: 0.6817 - val_loss: 0.4906 - val_accuracy: 0.8629\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 1s 140ms/step - loss: 0.8415 - accuracy: 0.6971 - val_loss: 0.4826 - val_accuracy: 0.8647\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 0.8723 - accuracy: 0.6886 - val_loss: 0.4788 - val_accuracy: 0.8711\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 0.8315 - accuracy: 0.7044 - val_loss: 0.4946 - val_accuracy: 0.8396\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 1s 143ms/step - loss: 0.8926 - accuracy: 0.6820 - val_loss: 0.4585 - val_accuracy: 0.8702\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 1s 134ms/step - loss: 0.8295 - accuracy: 0.7027 - val_loss: 0.4440 - val_accuracy: 0.8678\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 1s 134ms/step - loss: 0.8123 - accuracy: 0.7073 - val_loss: 0.4138 - val_accuracy: 0.8969\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 0.7958 - accuracy: 0.7176 - val_loss: 0.4149 - val_accuracy: 0.8869\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 0.7580 - accuracy: 0.7342 - val_loss: 0.3800 - val_accuracy: 0.8889\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 0.7351 - accuracy: 0.7330 - val_loss: 0.3489 - val_accuracy: 0.9097\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 0.6991 - accuracy: 0.7475 - val_loss: 0.3622 - val_accuracy: 0.9033\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 1s 140ms/step - loss: 0.7061 - accuracy: 0.7455 - val_loss: 0.3523 - val_accuracy: 0.9119\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 0.7009 - accuracy: 0.7531 - val_loss: 0.3338 - val_accuracy: 0.9221\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 1s 138ms/step - loss: 0.6776 - accuracy: 0.7570 - val_loss: 0.2972 - val_accuracy: 0.9242\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 0.6417 - accuracy: 0.7692 - val_loss: 0.3008 - val_accuracy: 0.9197\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 0.6349 - accuracy: 0.7735 - val_loss: 0.2837 - val_accuracy: 0.9293\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 0.6123 - accuracy: 0.7801 - val_loss: 0.2566 - val_accuracy: 0.9363\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 0.5849 - accuracy: 0.7919 - val_loss: 0.2742 - val_accuracy: 0.9250\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.8514 - accuracy: 0.7331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8514356017112732, 0.7331288456916809]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5IKmk7D49_n"
      },
      "source": [
        "## Task 2: Optimize the model\n",
        "\n",
        "Experiment with the following:\n",
        "\n",
        "* number of hidden layers \n",
        "* number of nodes in each layer\n",
        "* dropout regularization rate\n",
        "\n",
        "What trends did you discover?  Can you reach at least 98% accuracy against the test set? \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYG5qXpP5a9n"
      },
      "source": [
        "#@title Double-click to view some possible answers.\n",
        "\n",
        "# It would take much too long to experiment \n",
        "# fully with topography and dropout regularization \n",
        "# rate. In the real world, you would\n",
        "# also experiment with learning rate, batch size, \n",
        "# and number of epochs.  Since you only have a \n",
        "# few minutes, searching for trends can be helpful.\n",
        "# Here is what we discovered:\n",
        "#   * Adding more nodes (at least until 256 nodes) \n",
        "#     to the first hidden layer improved accuracy.\n",
        "#   * Adding a second hidden layer generally \n",
        "#     improved accuracy.\n",
        "#   * When the model contains a lot of nodes, \n",
        "#     the model overfits unless the dropout rate \n",
        "#     is at least 0.5. \n",
        "\n",
        "# We reached 98% test accuracy with the \n",
        "# following configuration:\n",
        "#   * One hidden layer of 256 nodes; no second hidden layer.\n",
        "#   * dropout regularization rate of 0.4\n",
        "\n",
        "# We reached 98.2% test accuracy with the \n",
        "# following configuration:\n",
        "#   * First hidden layer of 256 nodes; \n",
        "#     second hidden layer of 128 nodes.\n",
        "#   * dropout regularization rate of 0.2\n",
        "\n",
        "# MAT-> 98.34% test accuracy with the \n",
        "# following configuration:\n",
        "#   * First hidden layer of 256 nodes; \n",
        "#     2nd, 3rd hidden layer of 256 nodes.\n",
        "#   * dropout regularization rate of 0.4\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}